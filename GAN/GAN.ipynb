{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "GAN.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "metadata": {
        "id": "iFosZOh_2OZC",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import os, time\n",
        "import matplotlib.pyplot as plt\n",
        "import itertools\n",
        "import pickle\n",
        "import imageio\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "from torchvision import datasets, transforms\n",
        "from torch.autograd import Variable\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "IDyDAZPWipxH",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "class Generator(nn.Module):\n",
        "  def __init__(self, d=128):\n",
        "    super(Generator, self).__init__()\n",
        "    self.deconv1 = nn.ConvTranspose2d(100,d*8,4,1,0)\n",
        "    self.bn1 = nn.BatchNorm2d(d*8)\n",
        "    self.deconv2 = nn.ConvTranspose2d(d*8,d*4,4,2,1)\n",
        "    self.bn2 = nn.BatchNorm2d(d*4)\n",
        "    self.deconv3 = nn.ConvTranspose2d(d*4,d*2,4,2,1)\n",
        "    self.bn3 = nn.BatchNorm2d(d*2)\n",
        "    self.deconv4 = nn.ConvTranspose2d(d*2,d,4,2,1)\n",
        "    self.bn4 = nn.BatchNorm2d(d)\n",
        "    self.deconv5 = nn.ConvTranspose2d(d,1,4,2,1)\n",
        "    \n",
        "  def forward(self, x):\n",
        "    x = F.relu(self.bn1(self.deconv1(x)))\n",
        "    x = F.relu(self.bn2(self.deconv2(x)))\n",
        "    x = F.relu(self.bn3(self.deconv3(x)))\n",
        "    x = F.relu(self.bn4(self.deconv4(x)))\n",
        "    x = F.tanh(self.deconv5(x)) # GAN_hacks as it works better \n",
        "    return x"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "U--Vt7CRuwMs",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "class Discriminator(nn.Module):\n",
        "  def __init__(self, d=128):\n",
        "    super(Discriminator, self).__init__()\n",
        "    self.conv1 = nn.Conv2d(1,d,4,2,1)\n",
        "    self.conv2 = nn.Conv2d(d,d*2,4,2,1)\n",
        "    self.bn2 = nn.BatchNorm2d(d*2)\n",
        "    self.conv3 = nn.Conv2d(d*2,d*4,4,2,1)\n",
        "    self.bn3 = nn.BatchNorm2d(d*4)\n",
        "    self.conv4 = nn.Conv2d(d*4,d*8,4,2,1)\n",
        "    self.bn4 =nn.BatchNorm2d(d*8)\n",
        "    self.conv5 = nn.Conv2d(d*8,1,4,1,0)\n",
        "    \n",
        "  def forward(self, x):\n",
        "    x = F.leaky_relu(self.conv1(x),0.2)\n",
        "    x = F.leaky_relu(self.bn2(self.conv2(x)), 0.2)\n",
        "    x = F.leaky_relu(self.bn3(self.conv3(x)), 0.2)\n",
        "    x = F.leaky_relu(self.bn4(self.conv4(x)), 0.2)\n",
        "    x = F.sigmoid(self.conv5(x))\n",
        "    return x"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "OF0RKZhbxVv7",
        "colab_type": "code",
        "outputId": "95d58ea0-61a9-49ab-ac99-56d036a1a3b5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 73
        }
      },
      "cell_type": "code",
      "source": [
        "fixed_z_ = torch.randn((5*5,100)).view(-1,100,1,1)\n",
        "fixed_z_ = Variable(fixed_z_.cuda(), volatile = True)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:2: UserWarning: volatile was removed and now has no effect. Use `with torch.no_grad():` instead.\n",
            "  \n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "metadata": {
        "id": "4zSdtWAH2FtB",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def show_result(num_epoch, show = False, save = True, path = 'result.png', isFix=False):\n",
        "    z_ = torch.randn((5*5, 100)).view(-1, 100, 1, 1)\n",
        "    z_ = Variable(z_.cuda(), volatile=True)\n",
        "\n",
        "    G.eval()\n",
        "    if isFix:\n",
        "        test_images = G(fixed_z_)\n",
        "    else:\n",
        "        test_images = G(z_)\n",
        "    G.train()\n",
        "\n",
        "    size_figure_grid = 5\n",
        "    fig, ax = plt.subplots(size_figure_grid, size_figure_grid, figsize=(5, 5))\n",
        "    for i, j in itertools.product(range(size_figure_grid), range(size_figure_grid)):\n",
        "        ax[i, j].get_xaxis().set_visible(False)\n",
        "        ax[i, j].get_yaxis().set_visible(False)\n",
        "\n",
        "    for k in range(5*5):\n",
        "        i = k // 5\n",
        "        j = k % 5\n",
        "        ax[i, j].cla()\n",
        "        ax[i, j].imshow(test_images[k, 0].cpu().data.numpy(), cmap='gray')\n",
        "\n",
        "    label = 'Epoch {0}'.format(num_epoch)\n",
        "    fig.text(0.5, 0.04, label, ha='center')\n",
        "    plt.savefig(path)\n",
        "\n",
        "    if show:\n",
        "        plt.show()\n",
        "    else:\n",
        "        plt.close()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "YqMpVxA12kga",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def show_train_hist(hist, show = False, save = True, path = 'Train_hist.png'):\n",
        "    x = range(len(hist['D_losses']))\n",
        "\n",
        "    y1 = hist['D_losses']\n",
        "    y2 = hist['G_losses']\n",
        "\n",
        "    plt.plot(x, y1, label='D_loss')\n",
        "    plt.plot(x, y2, label='G_loss')\n",
        "\n",
        "    plt.xlabel('Iter')\n",
        "    plt.ylabel('Loss')\n",
        "\n",
        "    plt.legend(loc=4)\n",
        "    plt.grid(True)\n",
        "    plt.tight_layout()\n",
        "\n",
        "    if save:\n",
        "        plt.savefig(path)\n",
        "\n",
        "    if show:\n",
        "        plt.show()\n",
        "    else:\n",
        "        plt.close()\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "6jQGDtv525U7",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#Training Parameters\n",
        "batch_size = 128\n",
        "lr = 0.0002\n",
        "epochs = 2"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "sMOSPcWq3I5C",
        "colab_type": "code",
        "outputId": "efcd3a48-770f-4dfa-cc09-3f043ee53b71",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 177
        }
      },
      "cell_type": "code",
      "source": [
        "img_size = 64\n",
        "transform = transforms.Compose([transforms.Scale(img_size),transforms.ToTensor(),\n",
        "                               transforms.Normalize(mean=(0.5,0.5,0.5),std=(0.5,0.5,0.5))])\n",
        "\n",
        "train_loader = torch.utils.data.DataLoader(datasets.MNIST('data',train = 'True',\n",
        "                                                         download=True,transform=transform),\n",
        "                                          batch_size=batch_size,shuffle = True)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/torchvision/transforms/transforms.py:188: UserWarning: The use of the transforms.Scale transform is deprecated, please use transforms.Resize instead.\n",
            "  \"please use transforms.Resize instead.\")\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz\n",
            "Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz\n",
            "Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz\n",
            "Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz\n",
            "Processing...\n",
            "Done!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "yWUC-NCB69_i",
        "colab_type": "code",
        "outputId": "b6e99c89-0905-49ff-ed73-bec00d03b940",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 191
        }
      },
      "cell_type": "code",
      "source": [
        "# Defining Model\n",
        "G = Generator(128)\n",
        "D = Discriminator(128)\n",
        "G.cuda()\n",
        "D.cuda()\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Discriminator(\n",
              "  (conv1): Conv2d(1, 128, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))\n",
              "  (conv2): Conv2d(128, 256, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))\n",
              "  (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "  (conv3): Conv2d(256, 512, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))\n",
              "  (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "  (conv4): Conv2d(512, 1024, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))\n",
              "  (bn4): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "  (conv5): Conv2d(1024, 1, kernel_size=(4, 4), stride=(1, 1))\n",
              ")"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "metadata": {
        "id": "Tvxks2gs71mI",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Define Loss Function\n",
        "loss = nn.BCELoss()\n",
        "\n",
        "# Define Adam optimizers\n",
        "G_optimizer = optim.Adam(G.parameters(),lr = lr, betas=(0.5,0.999))\n",
        "D_optimizer = optim.Adam(D.parameters(), lr=lr, betas = (0.5,0.999))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "RCWspAWv8V54",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "train_hist = {}\n",
        "train_hist['D_losses'] = []\n",
        "train_hist['G_losses'] = []\n",
        "train_hist['per_epoch_ptimes'] = []\n",
        "train_hist['total_ptime'] = []"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "6lYPQpP9-AXl",
        "colab_type": "code",
        "outputId": "15051df3-c155-4dd6-a976-c0ac24ab6a1b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 3149
        }
      },
      "cell_type": "code",
      "source": [
        "num_iters = 0\n",
        "print(\"Training Starts!!\")\n",
        "start_time = time.time()\n",
        "for epoch in range(epochs):\n",
        "  D_losses = []\n",
        "  G_losses = []\n",
        "  epoch_start_time = time.time()\n",
        "  for x_,_ in train_loader:\n",
        "    #  Train Discriminator   D:G == 1:1\n",
        "    D.zero_grad()\n",
        "    mini_batch = x_.size()[0]\n",
        "    y_real_ = torch.ones(mini_batch)\n",
        "    y_fake_ = torch.zeros(mini_batch)\n",
        "    x_, y_real_, y_fake_ = Variable(x_.cuda()),Variable(y_real_.cuda()),Variable(y_fake_.cuda())\n",
        "    D_result = D(x_).squeeze()\n",
        "    D_real_loss = loss(D_result, y_real_)\n",
        "    \n",
        "    z_sampled = torch.randn((mini_batch,100)).view(-1,100,1,1)\n",
        "    z_sampled = Variable(z_sampled.cuda())\n",
        "    G_result = G(z_sampled)\n",
        "    D_result = D(G_result).squeeze()\n",
        "    D_fake_loss = loss(D_result,y_fake_)\n",
        "    D_fake_score = D_result.data.mean()\n",
        "    \n",
        "    D_total_loss = D_real_loss + D_fake_loss\n",
        "    D_total_loss.backward()\n",
        "    D_optimizer.step()\n",
        "    \n",
        "    D_losses.append(D_total_loss.item())\n",
        "    \n",
        "    #   Train Generator\n",
        "    G.zero_grad()\n",
        "    z_sampled = torch.randn((mini_batch,100)).view(-1,100,1,1)\n",
        "    z_sampled = Variable(z_sampled.cuda())\n",
        "    G_result = G(z_sampled)\n",
        "    D_result = D(G_result).squeeze()\n",
        "    G_loss = loss(D_result, y_real_)\n",
        "    G_loss.backward()\n",
        "    G_optimizer.step()\n",
        "    \n",
        "    G_losses.append(G_loss.item())\n",
        "    \n",
        "    num_iters += 1\n",
        "    if num_iters%20 == 0:\n",
        "      print(\"Iterations occured :\",num_iters,\" D_loss :\",D_total_loss.item(),\" G_loss :\",G_loss.item())\n",
        "  \n",
        "  epoch_end_time = time.time()\n",
        "  \n",
        "  per_epoch_time = epoch_end_time - epoch_start_time\n",
        "  \n",
        "  print('[%d/%d] - ptime: %.2f, loss_d: %.3f, loss_g: %.3f' % ((epoch + 1), epochs, per_epoch_time, torch.mean(torch.FloatTensor(D_losses)),\n",
        "                                                              torch.mean(torch.FloatTensor(G_losses))))\n",
        "  p = str(epoch + 1) + '.png'\n",
        "  fixed_p = str(epoch + 1) + '.png'\n",
        "  show_result((epoch+1), save=True, path=p, isFix=False)\n",
        "  show_result((epoch+1), save=True, path=fixed_p, isFix=True)\n",
        "  train_hist['D_losses'].append(torch.mean(torch.FloatTensor(D_losses)))\n",
        "  train_hist['G_losses'].append(torch.mean(torch.FloatTensor(G_losses)))\n",
        "  train_hist['per_epoch_ptimes'].append(per_epoch_time)\n",
        "  \n",
        "\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Training Starts!!\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/torch/nn/functional.py:1332: UserWarning: nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\n",
            "  warnings.warn(\"nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\")\n",
            "/usr/local/lib/python3.6/dist-packages/torch/nn/functional.py:1320: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
            "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Iterations occured : 20  D_loss : 0.015724992379546165  G_loss : 6.936120510101318\n",
            "Iterations occured : 40  D_loss : 0.005871393717825413  G_loss : 6.826488494873047\n",
            "Iterations occured : 60  D_loss : 0.00560090783983469  G_loss : 7.0915045738220215\n",
            "Iterations occured : 80  D_loss : 1.317993402481079  G_loss : 2.5987672805786133\n",
            "Iterations occured : 100  D_loss : 0.41862428188323975  G_loss : 2.426618814468384\n",
            "Iterations occured : 120  D_loss : 0.6542184352874756  G_loss : 2.273446559906006\n",
            "Iterations occured : 140  D_loss : 1.296753168106079  G_loss : 1.817238688468933\n",
            "Iterations occured : 160  D_loss : 0.8057482838630676  G_loss : 4.284806728363037\n",
            "Iterations occured : 180  D_loss : 1.4548671245574951  G_loss : 1.9282777309417725\n",
            "Iterations occured : 200  D_loss : 1.162239670753479  G_loss : 1.8851103782653809\n",
            "Iterations occured : 220  D_loss : 0.8248867988586426  G_loss : 1.6100919246673584\n",
            "Iterations occured : 240  D_loss : 0.8248025178909302  G_loss : 0.45100805163383484\n",
            "Iterations occured : 260  D_loss : 1.1812348365783691  G_loss : 1.2855600118637085\n",
            "Iterations occured : 280  D_loss : 0.9349751472473145  G_loss : 1.7300481796264648\n",
            "Iterations occured : 300  D_loss : 1.7217437028884888  G_loss : 0.6451390981674194\n",
            "Iterations occured : 320  D_loss : 1.6789968013763428  G_loss : 0.5732731819152832\n",
            "Iterations occured : 340  D_loss : 1.1258119344711304  G_loss : 1.078125\n",
            "Iterations occured : 360  D_loss : 1.4955127239227295  G_loss : 1.3272783756256104\n",
            "Iterations occured : 380  D_loss : 1.0811585187911987  G_loss : 1.3961797952651978\n",
            "Iterations occured : 400  D_loss : 0.7454806566238403  G_loss : 1.5579841136932373\n",
            "Iterations occured : 420  D_loss : 0.7977190613746643  G_loss : 1.2467024326324463\n",
            "Iterations occured : 440  D_loss : 0.8370351195335388  G_loss : 2.9916796684265137\n",
            "Iterations occured : 460  D_loss : 0.645155131816864  G_loss : 1.447249412536621\n",
            "[1/7] - ptime: 820.81, loss_d: 0.872, loss_g: 2.678\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:3: UserWarning: volatile was removed and now has no effect. Use `with torch.no_grad():` instead.\n",
            "  This is separate from the ipykernel package so we can avoid doing imports until\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Iterations occured : 480  D_loss : 1.0464916229248047  G_loss : 2.5303244590759277\n",
            "Iterations occured : 500  D_loss : 0.6727755069732666  G_loss : 2.981663703918457\n",
            "Iterations occured : 520  D_loss : 0.8999950885772705  G_loss : 1.108676552772522\n",
            "Iterations occured : 540  D_loss : 1.2794677019119263  G_loss : 3.2648234367370605\n",
            "Iterations occured : 560  D_loss : 0.9696221947669983  G_loss : 3.142409563064575\n",
            "Iterations occured : 580  D_loss : 1.0331957340240479  G_loss : 2.346543550491333\n",
            "Iterations occured : 600  D_loss : 0.9195282459259033  G_loss : 0.8211212754249573\n",
            "Iterations occured : 620  D_loss : 0.7833235263824463  G_loss : 2.170616388320923\n",
            "Iterations occured : 640  D_loss : 0.7825809717178345  G_loss : 1.0260231494903564\n",
            "Iterations occured : 660  D_loss : 1.1929975748062134  G_loss : 3.477729320526123\n",
            "Iterations occured : 680  D_loss : 0.8346942663192749  G_loss : 2.6266255378723145\n",
            "Iterations occured : 700  D_loss : 0.8791630864143372  G_loss : 2.3139796257019043\n",
            "Iterations occured : 720  D_loss : 0.910597562789917  G_loss : 1.6745330095291138\n",
            "Iterations occured : 740  D_loss : 0.8397663831710815  G_loss : 2.620151996612549\n",
            "Iterations occured : 760  D_loss : 0.7359908819198608  G_loss : 2.54433274269104\n",
            "Iterations occured : 780  D_loss : 1.2136175632476807  G_loss : 3.1069395542144775\n",
            "Iterations occured : 800  D_loss : 0.7443353533744812  G_loss : 2.714968204498291\n",
            "Iterations occured : 820  D_loss : 0.7924041152000427  G_loss : 2.0667433738708496\n",
            "Iterations occured : 840  D_loss : 1.2336808443069458  G_loss : 2.852064371109009\n",
            "Iterations occured : 860  D_loss : 1.0871672630310059  G_loss : 1.081799030303955\n",
            "Iterations occured : 880  D_loss : 1.156609058380127  G_loss : 1.2019039392471313\n",
            "Iterations occured : 900  D_loss : 1.2299854755401611  G_loss : 2.892899513244629\n",
            "Iterations occured : 920  D_loss : 1.2123196125030518  G_loss : 2.146210193634033\n",
            "[2/7] - ptime: 821.66, loss_d: 0.945, loss_g: 1.647\n",
            "Iterations occured : 940  D_loss : 0.696674108505249  G_loss : 1.1516411304473877\n",
            "Iterations occured : 960  D_loss : 1.1024748086929321  G_loss : 1.2455979585647583\n",
            "Iterations occured : 980  D_loss : 0.4847693145275116  G_loss : 3.136704921722412\n",
            "Iterations occured : 1000  D_loss : 0.8379481434822083  G_loss : 1.5547685623168945\n",
            "Iterations occured : 1020  D_loss : 0.9562740921974182  G_loss : 1.4284276962280273\n",
            "Iterations occured : 1040  D_loss : 0.7916988134384155  G_loss : 1.5806694030761719\n",
            "Iterations occured : 1060  D_loss : 0.8619311451911926  G_loss : 1.824495792388916\n",
            "Iterations occured : 1080  D_loss : 1.161933422088623  G_loss : 1.2246220111846924\n",
            "Iterations occured : 1100  D_loss : 0.6299451589584351  G_loss : 2.708261013031006\n",
            "Iterations occured : 1120  D_loss : 0.8917597532272339  G_loss : 3.0835084915161133\n",
            "Iterations occured : 1140  D_loss : 0.8415433168411255  G_loss : 2.1348633766174316\n",
            "Iterations occured : 1160  D_loss : 0.8164116144180298  G_loss : 2.53666090965271\n",
            "Iterations occured : 1180  D_loss : 0.46900150179862976  G_loss : 3.551818370819092\n",
            "Iterations occured : 1200  D_loss : 0.03216360881924629  G_loss : 6.114584922790527\n",
            "Iterations occured : 1220  D_loss : 0.0812334418296814  G_loss : 9.30905532836914\n",
            "Iterations occured : 1240  D_loss : 0.015391942113637924  G_loss : 7.034425735473633\n",
            "Iterations occured : 1260  D_loss : 0.006603199988603592  G_loss : 6.945654392242432\n",
            "Iterations occured : 1280  D_loss : 0.004058339167386293  G_loss : 7.115302562713623\n",
            "Iterations occured : 1300  D_loss : 0.0019176318310201168  G_loss : 8.68032455444336\n",
            "Iterations occured : 1320  D_loss : 0.003559620352461934  G_loss : 9.653214454650879\n",
            "Iterations occured : 1340  D_loss : 1.9039666652679443  G_loss : 3.430500510148704e-05\n",
            "Iterations occured : 1360  D_loss : 0.4567889869213104  G_loss : 6.119153022766113\n",
            "Iterations occured : 1380  D_loss : 0.2053094506263733  G_loss : 5.336163520812988\n",
            "Iterations occured : 1400  D_loss : 0.2996300458908081  G_loss : 1.977291464805603\n",
            "[3/7] - ptime: 821.67, loss_d: 0.540, loss_g: 4.293\n",
            "Iterations occured : 1420  D_loss : 0.2042076140642166  G_loss : 3.2497074604034424\n",
            "Iterations occured : 1440  D_loss : 0.4050319790840149  G_loss : 2.3188059329986572\n",
            "Iterations occured : 1460  D_loss : 0.936952531337738  G_loss : 4.674499988555908\n",
            "Iterations occured : 1480  D_loss : 1.1485259532928467  G_loss : 3.8082385063171387\n",
            "Iterations occured : 1500  D_loss : 0.9760822057723999  G_loss : 0.7380653023719788\n",
            "Iterations occured : 1520  D_loss : 0.6247983574867249  G_loss : 1.5896666049957275\n",
            "Iterations occured : 1540  D_loss : 0.6238552331924438  G_loss : 4.299412727355957\n",
            "Iterations occured : 1560  D_loss : 0.5653039813041687  G_loss : 2.00036883354187\n",
            "Iterations occured : 1580  D_loss : 1.4932622909545898  G_loss : 2.746375560760498\n",
            "Iterations occured : 1600  D_loss : 0.3837817311286926  G_loss : 2.5182042121887207\n",
            "Iterations occured : 1620  D_loss : 1.169837474822998  G_loss : 3.849666118621826\n",
            "Iterations occured : 1640  D_loss : 0.8057866096496582  G_loss : 3.8718841075897217\n",
            "Iterations occured : 1660  D_loss : 0.15999338030815125  G_loss : 4.310208797454834\n",
            "Iterations occured : 1680  D_loss : 0.15310920774936676  G_loss : 2.786886692047119\n",
            "Iterations occured : 1700  D_loss : 0.44795843958854675  G_loss : 0.10791367292404175\n",
            "Iterations occured : 1720  D_loss : 0.5726474523544312  G_loss : 2.0530478954315186\n",
            "Iterations occured : 1740  D_loss : 0.39863404631614685  G_loss : 3.08895206451416\n",
            "Iterations occured : 1760  D_loss : 0.6320487260818481  G_loss : 1.1756031513214111\n",
            "Iterations occured : 1780  D_loss : 0.38258761167526245  G_loss : 1.7957667112350464\n",
            "Iterations occured : 1800  D_loss : 1.040837049484253  G_loss : 6.587378025054932\n",
            "Iterations occured : 1820  D_loss : 0.5040814280509949  G_loss : 3.3139915466308594\n",
            "Iterations occured : 1840  D_loss : 0.4774096608161926  G_loss : 1.8975813388824463\n",
            "Iterations occured : 1860  D_loss : 0.20640996098518372  G_loss : 3.5951457023620605\n",
            "[4/7] - ptime: 821.90, loss_d: 0.632, loss_g: 2.747\n",
            "Iterations occured : 1880  D_loss : 0.2418030947446823  G_loss : 1.8942971229553223\n",
            "Iterations occured : 1900  D_loss : 0.25125300884246826  G_loss : 4.278777122497559\n",
            "Iterations occured : 1920  D_loss : 0.3414517641067505  G_loss : 3.4347355365753174\n",
            "Iterations occured : 1940  D_loss : 0.04198630899190903  G_loss : 3.3558969497680664\n",
            "Iterations occured : 1960  D_loss : 0.04287755861878395  G_loss : 4.9536309242248535\n",
            "Iterations occured : 1980  D_loss : 0.8814089298248291  G_loss : 1.4382392168045044\n",
            "Iterations occured : 2000  D_loss : 0.4339408874511719  G_loss : 3.2061362266540527\n",
            "Iterations occured : 2020  D_loss : 0.4978196918964386  G_loss : 0.5319440364837646\n",
            "Iterations occured : 2040  D_loss : 0.3397364616394043  G_loss : 3.022526741027832\n",
            "Iterations occured : 2060  D_loss : 0.19552244246006012  G_loss : 5.742062091827393\n",
            "Iterations occured : 2080  D_loss : 0.2674661874771118  G_loss : 1.6170024871826172\n",
            "Iterations occured : 2100  D_loss : 1.8567887544631958  G_loss : 5.615386486053467\n",
            "Iterations occured : 2120  D_loss : 0.6626741886138916  G_loss : 3.9051761627197266\n",
            "Iterations occured : 2140  D_loss : 0.6230449676513672  G_loss : 7.024326324462891\n",
            "Iterations occured : 2160  D_loss : 0.5444442629814148  G_loss : 1.6650444269180298\n",
            "Iterations occured : 2180  D_loss : 0.1972724199295044  G_loss : 3.0961079597473145\n",
            "Iterations occured : 2200  D_loss : 0.06928622722625732  G_loss : 4.495624542236328\n",
            "Iterations occured : 2220  D_loss : 0.020976485684514046  G_loss : 5.661805152893066\n",
            "Iterations occured : 2240  D_loss : 0.04114532098174095  G_loss : 4.963347434997559\n",
            "Iterations occured : 2260  D_loss : 0.06500481069087982  G_loss : 5.216533660888672\n",
            "Iterations occured : 2280  D_loss : 2.314387798309326  G_loss : 0.04323925822973251\n",
            "Iterations occured : 2300  D_loss : 0.45132243633270264  G_loss : 2.1525747776031494\n",
            "Iterations occured : 2320  D_loss : 0.8412322402000427  G_loss : 2.33878231048584\n",
            "Iterations occured : 2340  D_loss : 0.7669926881790161  G_loss : 5.721441745758057\n",
            "[5/7] - ptime: 821.60, loss_d: 0.509, loss_g: 3.452\n",
            "Iterations occured : 2360  D_loss : 0.2888707220554352  G_loss : 2.1196939945220947\n",
            "Iterations occured : 2380  D_loss : 1.9064593315124512  G_loss : 1.6407767534255981\n",
            "Iterations occured : 2400  D_loss : 0.8843867778778076  G_loss : 3.711393356323242\n",
            "Iterations occured : 2420  D_loss : 0.5992935299873352  G_loss : 3.0880355834960938\n",
            "Iterations occured : 2440  D_loss : 0.8278676271438599  G_loss : 2.5500221252441406\n",
            "Iterations occured : 2460  D_loss : 0.9946633577346802  G_loss : 6.39976167678833\n",
            "Iterations occured : 2480  D_loss : 0.24435728788375854  G_loss : 3.396049737930298\n",
            "Iterations occured : 2500  D_loss : 1.346754789352417  G_loss : 4.167682647705078\n",
            "Iterations occured : 2520  D_loss : 0.36774513125419617  G_loss : 2.942133903503418\n",
            "Iterations occured : 2540  D_loss : 0.4125586748123169  G_loss : 3.934530019760132\n",
            "Iterations occured : 2560  D_loss : 0.09344791620969772  G_loss : 3.3496603965759277\n",
            "Iterations occured : 2580  D_loss : 0.07356822490692139  G_loss : 4.2146453857421875\n",
            "Iterations occured : 2600  D_loss : 0.08994375169277191  G_loss : 4.58458137512207\n",
            "Iterations occured : 2620  D_loss : 0.23888036608695984  G_loss : 2.9272420406341553\n",
            "Iterations occured : 2640  D_loss : 0.4759230315685272  G_loss : 0.9298071265220642\n",
            "Iterations occured : 2660  D_loss : 0.587855875492096  G_loss : 2.596184492111206\n",
            "Iterations occured : 2680  D_loss : 1.5684311389923096  G_loss : 1.1957365274429321\n",
            "Iterations occured : 2700  D_loss : 0.17162378132343292  G_loss : 3.260376214981079\n",
            "Iterations occured : 2720  D_loss : 0.20668408274650574  G_loss : 2.377725601196289\n",
            "Iterations occured : 2740  D_loss : 0.11641908437013626  G_loss : 5.061164379119873\n",
            "Iterations occured : 2760  D_loss : 0.024086836725473404  G_loss : 5.045492172241211\n",
            "Iterations occured : 2780  D_loss : 0.06595385074615479  G_loss : 4.795103549957275\n",
            "Iterations occured : 2800  D_loss : 9.092945098876953  G_loss : 2.5042014122009277\n",
            "[6/7] - ptime: 821.77, loss_d: 0.518, loss_g: 3.226\n",
            "Iterations occured : 2820  D_loss : 0.21994346380233765  G_loss : 4.359550476074219\n",
            "Iterations occured : 2840  D_loss : 0.4394720494747162  G_loss : 4.996426105499268\n",
            "Iterations occured : 2860  D_loss : 0.49823465943336487  G_loss : 3.753415822982788\n",
            "Iterations occured : 2880  D_loss : 0.09761448204517365  G_loss : 3.8345465660095215\n",
            "Iterations occured : 2900  D_loss : 0.07632842659950256  G_loss : 3.9963808059692383\n",
            "Iterations occured : 2920  D_loss : 0.046446602791547775  G_loss : 4.995027542114258\n",
            "Iterations occured : 2940  D_loss : 0.062174081802368164  G_loss : 5.458249092102051\n",
            "Iterations occured : 2960  D_loss : 2.0727739334106445  G_loss : 8.112409591674805\n",
            "Iterations occured : 2980  D_loss : 0.24955381453037262  G_loss : 2.2919294834136963\n",
            "Iterations occured : 3000  D_loss : 0.6997942328453064  G_loss : 4.453431129455566\n",
            "Iterations occured : 3020  D_loss : 0.6818630695343018  G_loss : 3.066535472869873\n",
            "Iterations occured : 3040  D_loss : 2.63120436668396  G_loss : 4.792297840118408\n",
            "Iterations occured : 3060  D_loss : 0.4854663014411926  G_loss : 3.611635208129883\n",
            "Iterations occured : 3080  D_loss : 0.16992907226085663  G_loss : 3.70000958442688\n",
            "Iterations occured : 3100  D_loss : 0.03819175437092781  G_loss : 4.339791297912598\n",
            "Iterations occured : 3120  D_loss : 0.03578300401568413  G_loss : 3.7074339389801025\n",
            "Iterations occured : 3140  D_loss : 0.017540782690048218  G_loss : 5.7397003173828125\n",
            "Iterations occured : 3160  D_loss : 0.03709372133016586  G_loss : 4.82143497467041\n",
            "Iterations occured : 3180  D_loss : 1.1848794221878052  G_loss : 1.967736005783081\n",
            "Iterations occured : 3200  D_loss : 0.8062256574630737  G_loss : 2.3418474197387695\n",
            "Iterations occured : 3220  D_loss : 1.0917346477508545  G_loss : 2.562089443206787\n",
            "Iterations occured : 3240  D_loss : 0.7898509502410889  G_loss : 1.639096736907959\n",
            "Iterations occured : 3260  D_loss : 0.5911850929260254  G_loss : 2.043595790863037\n",
            "Iterations occured : 3280  D_loss : 0.7121649384498596  G_loss : 2.3642020225524902\n",
            "[7/7] - ptime: 821.42, loss_d: 0.495, loss_g: 3.478\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "uUdCPYPqJqk_",
        "colab_type": "code",
        "outputId": "54b49879-f8c6-4cee-f5da-df8f42fd4d3b",
        "colab": {
          "resources": {
            "http://localhost:18536/content/generator_param.pkl": {
              "data": "CjwhRE9DVFlQRSBodG1sPgo8aHRtbCBsYW5nPWVuPgogIDxtZXRhIGNoYXJzZXQ9dXRmLTg+CiAgPG1ldGEgbmFtZT12aWV3cG9ydCBjb250ZW50PSJpbml0aWFsLXNjYWxlPTEsIG1pbmltdW0tc2NhbGU9MSwgd2lkdGg9ZGV2aWNlLXdpZHRoIj4KICA8dGl0bGU+RXJyb3IgNTAwIChJbnRlcm5hbCBTZXJ2ZXIgRXJyb3IpISExPC90aXRsZT4KICA8c3R5bGU+CiAgICAqe21hcmdpbjowO3BhZGRpbmc6MH1odG1sLGNvZGV7Zm9udDoxNXB4LzIycHggYXJpYWwsc2Fucy1zZXJpZn1odG1se2JhY2tncm91bmQ6I2ZmZjtjb2xvcjojMjIyO3BhZGRpbmc6MTVweH1ib2R5e21hcmdpbjo3JSBhdXRvIDA7bWF4LXdpZHRoOjM5MHB4O21pbi1oZWlnaHQ6MTgwcHg7cGFkZGluZzozMHB4IDAgMTVweH0qID4gYm9keXtiYWNrZ3JvdW5kOnVybCgvL3d3dy5nb29nbGUuY29tL2ltYWdlcy9lcnJvcnMvcm9ib3QucG5nKSAxMDAlIDVweCBuby1yZXBlYXQ7cGFkZGluZy1yaWdodDoyMDVweH1we21hcmdpbjoxMXB4IDAgMjJweDtvdmVyZmxvdzpoaWRkZW59aW5ze2NvbG9yOiM3Nzc7dGV4dC1kZWNvcmF0aW9uOm5vbmV9YSBpbWd7Ym9yZGVyOjB9QG1lZGlhIHNjcmVlbiBhbmQgKG1heC13aWR0aDo3NzJweCl7Ym9keXtiYWNrZ3JvdW5kOm5vbmU7bWFyZ2luLXRvcDowO21heC13aWR0aDpub25lO3BhZGRpbmctcmlnaHQ6MH19I2xvZ297YmFja2dyb3VuZDp1cmwoLy93d3cuZ29vZ2xlLmNvbS9pbWFnZXMvbG9nb3MvZXJyb3JwYWdlL2Vycm9yX2xvZ28tMTUweDU0LnBuZykgbm8tcmVwZWF0O21hcmdpbi1sZWZ0Oi01cHh9QG1lZGlhIG9ubHkgc2NyZWVuIGFuZCAobWluLXJlc29sdXRpb246MTkyZHBpKXsjbG9nb3tiYWNrZ3JvdW5kOnVybCgvL3d3dy5nb29nbGUuY29tL2ltYWdlcy9sb2dvcy9lcnJvcnBhZ2UvZXJyb3JfbG9nby0xNTB4NTQtMngucG5nKSBuby1yZXBlYXQgMCUgMCUvMTAwJSAxMDAlOy1tb3otYm9yZGVyLWltYWdlOnVybCgvL3d3dy5nb29nbGUuY29tL2ltYWdlcy9sb2dvcy9lcnJvcnBhZ2UvZXJyb3JfbG9nby0xNTB4NTQtMngucG5nKSAwfX1AbWVkaWEgb25seSBzY3JlZW4gYW5kICgtd2Via2l0LW1pbi1kZXZpY2UtcGl4ZWwtcmF0aW86Mil7I2xvZ297YmFja2dyb3VuZDp1cmwoLy93d3cuZ29vZ2xlLmNvbS9pbWFnZXMvbG9nb3MvZXJyb3JwYWdlL2Vycm9yX2xvZ28tMTUweDU0LTJ4LnBuZykgbm8tcmVwZWF0Oy13ZWJraXQtYmFja2dyb3VuZC1zaXplOjEwMCUgMTAwJX19I2xvZ297ZGlzcGxheTppbmxpbmUtYmxvY2s7aGVpZ2h0OjU0cHg7d2lkdGg6MTUwcHh9CiAgPC9zdHlsZT4KICA8YSBocmVmPS8vd3d3Lmdvb2dsZS5jb20vPjxzcGFuIGlkPWxvZ28gYXJpYS1sYWJlbD1Hb29nbGU+PC9zcGFuPjwvYT4KICA8cD48Yj41MDAuPC9iPiA8aW5zPlRoYXTigJlzIGFuIGVycm9yLjwvaW5zPgogIDxwPiAgPGlucz5UaGF04oCZcyBhbGwgd2Uga25vdy48L2lucz4K",
              "ok": false,
              "headers": [
                [
                  "content-length",
                  "1461"
                ],
                [
                  "content-type",
                  "text/html; charset=utf-8"
                ]
              ],
              "status": 500,
              "status_text": ""
            }
          },
          "base_uri": "https://localhost:8080/",
          "height": 621
        }
      },
      "cell_type": "code",
      "source": [
        "end_time = time.time()\n",
        "total_time = end_time - start_time\n",
        "train_hist['total_ptime'].append(total_time)\n",
        "print(\"Avg per epoch ptime: %.2f, total %d epochs ptime: %.2f\" % (torch.mean(torch.FloatTensor(train_hist['per_epoch_ptimes'])), epochs, total_time))\n",
        "print(\"Training finish!... save training results\")\n",
        "from google.colab import files\n",
        "torch.save(G.state_dict(), \"generator_param.pkl\")\n",
        "files.download(\"./generator_param.pkl\")\n",
        "torch.save(D.state_dict(), \"discriminator_param.pkl\")\n",
        "files.download(\"./discriminator_param.pkl\")\n",
        "with open('train_hist.pkl', 'wb') as f:\n",
        "    pickle.dump(train_hist, f)\n",
        "files.download('./train_hist.pkl')\n",
        "show_train_hist(train_hist, save=True, path='MNIST_DCGAN_train_hist.png')\n",
        "\n",
        "    "
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Avg per epoch ptime: 821.55, total 7 epochs ptime: 5768.17\n",
            "Training finish!... save training results\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-13-e8fef70abc19>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mgoogle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolab\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mfiles\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mG\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstate_dict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"generator_param.pkl\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m \u001b[0mfiles\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdownload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"./generator_param.pkl\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mD\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstate_dict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"discriminator_param.pkl\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0mfiles\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdownload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"./discriminator_param.pkl\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/google/colab/files.py\u001b[0m in \u001b[0;36mdownload\u001b[0;34m(filename)\u001b[0m\n\u001b[1;32m    176\u001b[0m       \u001b[0;34m'port'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mport\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    177\u001b[0m       \u001b[0;34m'path'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0m_os\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mabspath\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 178\u001b[0;31m       \u001b[0;34m'name'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0m_os\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbasename\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    179\u001b[0m   })\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/google/colab/output/_js.py\u001b[0m in \u001b[0;36meval_js\u001b[0;34m(script, ignore_result)\u001b[0m\n\u001b[1;32m     37\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0mignore_result\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     38\u001b[0m     \u001b[0;32mreturn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 39\u001b[0;31m   \u001b[0;32mreturn\u001b[0m \u001b[0m_message\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_reply_from_input\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrequest_id\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     40\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     41\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/google/colab/_message.py\u001b[0m in \u001b[0;36mread_reply_from_input\u001b[0;34m(message_id, timeout_sec)\u001b[0m\n\u001b[1;32m     99\u001b[0m     \u001b[0mreply\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_read_next_input_message\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    100\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mreply\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0m_NOT_READY\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreply\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 101\u001b[0;31m       \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msleep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0.025\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    102\u001b[0m       \u001b[0;32mcontinue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    103\u001b[0m     if (reply.get('type') == 'colab_reply' and\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "metadata": {
        "id": "-DZSBO9VPVw8",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "ls"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "vHA2y31xHOHN",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "\n",
        "images = []\n",
        "for e in range(epochs):\n",
        "    img_name =str(e + 1) + '.png'\n",
        "    images.append(imageio.imread(img_name))\n",
        "imageio.mimsave('generation_animation.gif', images, fps=5)\n",
        "files.download('./generation_animation.gif')    "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "sdQf-KfFHXcj",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}